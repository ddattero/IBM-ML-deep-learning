{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Country of Origin</th>\n",
       "      <th>Farm Name</th>\n",
       "      <th>Lot Number</th>\n",
       "      <th>Mill</th>\n",
       "      <th>ICO Number</th>\n",
       "      <th>Company</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Region</th>\n",
       "      <th>Producer</th>\n",
       "      <th>Number of Bags</th>\n",
       "      <th>Bag Weight</th>\n",
       "      <th>In-Country Partner</th>\n",
       "      <th>Harvest Year</th>\n",
       "      <th>Grading Date</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Status</th>\n",
       "      <th>Processing Method</th>\n",
       "      <th>Aroma</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Aftertaste</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Body</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Uniformity</th>\n",
       "      <th>Clean Cup</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Defects</th>\n",
       "      <th>Total Cup Points</th>\n",
       "      <th>Moisture Percentage</th>\n",
       "      <th>Category One Defects</th>\n",
       "      <th>Quakers</th>\n",
       "      <th>Color</th>\n",
       "      <th>Category Two Defects</th>\n",
       "      <th>Expiration</th>\n",
       "      <th>Certification Body</th>\n",
       "      <th>Certification Address</th>\n",
       "      <th>Certification Contact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Finca El Paraiso</td>\n",
       "      <td>CQU2022015</td>\n",
       "      <td>Finca El Paraiso</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Coffee Quality Union</td>\n",
       "      <td>1700-1930</td>\n",
       "      <td>Piendamo,Cauca</td>\n",
       "      <td>Diego Samuel Bermudez</td>\n",
       "      <td>1</td>\n",
       "      <td>35 kg</td>\n",
       "      <td>Japan Coffee Exchange</td>\n",
       "      <td>2021 / 2022</td>\n",
       "      <td>September 21st, 2022</td>\n",
       "      <td>Coffee Quality Union</td>\n",
       "      <td>Castillo</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Double Anaerobic Washed</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.33</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>green</td>\n",
       "      <td>3</td>\n",
       "      <td>September 21st, 2023</td>\n",
       "      <td>Japan Coffee Exchange</td>\n",
       "      <td>〒413-0002 静岡県熱海市伊豆山１１７３−５８ 1173-58 Izusan, Ata...</td>\n",
       "      <td>松澤　宏樹　Koju Matsuzawa - +81(0)9085642901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>Royal Bean Geisha Estate</td>\n",
       "      <td>The 2022 Pacific Rim Coffee Summit,T037</td>\n",
       "      <td>Royal Bean Geisha Estate</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Taiwan Coffee Laboratory</td>\n",
       "      <td>1200</td>\n",
       "      <td>Chiayi</td>\n",
       "      <td>曾福森</td>\n",
       "      <td>1</td>\n",
       "      <td>80 kg</td>\n",
       "      <td>Taiwan Coffee Laboratory 台灣咖啡研究室</td>\n",
       "      <td>2021 / 2022</td>\n",
       "      <td>November 15th, 2022</td>\n",
       "      <td>Taiwan Coffee Laboratory 台灣咖啡研究室</td>\n",
       "      <td>Gesha</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Washed / Wet</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.50</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>blue-green</td>\n",
       "      <td>0</td>\n",
       "      <td>November 15th, 2023</td>\n",
       "      <td>Taiwan Coffee Laboratory 台灣咖啡研究室</td>\n",
       "      <td>QAHWAH CO., LTD 4F, No. 225, Sec. 3, Beixin Rd...</td>\n",
       "      <td>Lin, Jen-An Neil 林仁安 - 886-289116612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Laos</td>\n",
       "      <td>OKLAO coffee farms</td>\n",
       "      <td>The 2022 Pacific Rim Coffee Summit,LA01</td>\n",
       "      <td>oklao coffee processing plant</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Taiwan Coffee Laboratory</td>\n",
       "      <td>1300</td>\n",
       "      <td>Laos Borofen Plateau</td>\n",
       "      <td>WU TAO CHI</td>\n",
       "      <td>19</td>\n",
       "      <td>25 kg</td>\n",
       "      <td>Taiwan Coffee Laboratory 台灣咖啡研究室</td>\n",
       "      <td>2021 / 2022</td>\n",
       "      <td>November 15th, 2022</td>\n",
       "      <td>Taiwan Coffee Laboratory 台灣咖啡研究室</td>\n",
       "      <td>Java</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Semi Washed</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.17</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.42</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yellowish</td>\n",
       "      <td>2</td>\n",
       "      <td>November 15th, 2023</td>\n",
       "      <td>Taiwan Coffee Laboratory 台灣咖啡研究室</td>\n",
       "      <td>QAHWAH CO., LTD 4F, No. 225, Sec. 3, Beixin Rd...</td>\n",
       "      <td>Lin, Jen-An Neil 林仁安 - 886-289116612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>La Cumbre</td>\n",
       "      <td>CQU2022017</td>\n",
       "      <td>La Montana Tarrazu MIll</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Coffee Quality Union</td>\n",
       "      <td>1900</td>\n",
       "      <td>Los Santos,Tarrazu</td>\n",
       "      <td>Santa Maria de Dota</td>\n",
       "      <td>1</td>\n",
       "      <td>22 kg</td>\n",
       "      <td>Japan Coffee Exchange</td>\n",
       "      <td>2022</td>\n",
       "      <td>September 21st, 2022</td>\n",
       "      <td>Coffee Quality Union</td>\n",
       "      <td>Gesha</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Washed / Wet</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.17</td>\n",
       "      <td>8.08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.17</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>September 21st, 2023</td>\n",
       "      <td>Japan Coffee Exchange</td>\n",
       "      <td>〒413-0002 静岡県熱海市伊豆山１１７３−５８ 1173-58 Izusan, Ata...</td>\n",
       "      <td>松澤　宏樹　Koju Matsuzawa - +81(0)9085642901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Finca Santuario</td>\n",
       "      <td>CQU2023002</td>\n",
       "      <td>Finca Santuario</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Coffee Quality Union</td>\n",
       "      <td>1850-2100</td>\n",
       "      <td>Popayan,Cauca</td>\n",
       "      <td>Camilo Merizalde</td>\n",
       "      <td>2</td>\n",
       "      <td>24 kg</td>\n",
       "      <td>Japan Coffee Exchange</td>\n",
       "      <td>2022</td>\n",
       "      <td>March 6th, 2023</td>\n",
       "      <td>Coffee Quality Union</td>\n",
       "      <td>Red Bourbon</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Honey,Mossto</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.25</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.08</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yellow-green</td>\n",
       "      <td>2</td>\n",
       "      <td>March 5th, 2024</td>\n",
       "      <td>Japan Coffee Exchange</td>\n",
       "      <td>〒413-0002 静岡県熱海市伊豆山１１７３−５８ 1173-58 Izusan, Ata...</td>\n",
       "      <td>松澤　宏樹　Koju Matsuzawa - +81(0)9085642901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID Country of Origin                 Farm Name  \\\n",
       "0           0   0          Colombia          Finca El Paraiso   \n",
       "1           1   1            Taiwan  Royal Bean Geisha Estate   \n",
       "2           2   2              Laos        OKLAO coffee farms   \n",
       "3           3   3        Costa Rica                 La Cumbre   \n",
       "4           4   4          Colombia           Finca Santuario   \n",
       "\n",
       "                                Lot Number                           Mill  \\\n",
       "0                               CQU2022015               Finca El Paraiso   \n",
       "1  The 2022 Pacific Rim Coffee Summit,T037       Royal Bean Geisha Estate   \n",
       "2  The 2022 Pacific Rim Coffee Summit,LA01  oklao coffee processing plant   \n",
       "3                               CQU2022017        La Montana Tarrazu MIll   \n",
       "4                               CQU2023002                Finca Santuario   \n",
       "\n",
       "  ICO Number                   Company   Altitude                Region  \\\n",
       "0        N/A      Coffee Quality Union  1700-1930        Piendamo,Cauca   \n",
       "1        N/A  Taiwan Coffee Laboratory       1200                Chiayi   \n",
       "2        N/A  Taiwan Coffee Laboratory       1300  Laos Borofen Plateau   \n",
       "3        N/A      Coffee Quality Union       1900    Los Santos,Tarrazu   \n",
       "4        N/A      Coffee Quality Union  1850-2100         Popayan,Cauca   \n",
       "\n",
       "                Producer  Number of Bags Bag Weight  \\\n",
       "0  Diego Samuel Bermudez               1      35 kg   \n",
       "1                    曾福森               1      80 kg   \n",
       "2             WU TAO CHI              19      25 kg   \n",
       "3    Santa Maria de Dota               1      22 kg   \n",
       "4       Camilo Merizalde               2      24 kg   \n",
       "\n",
       "                 In-Country Partner Harvest Year          Grading Date  \\\n",
       "0             Japan Coffee Exchange  2021 / 2022  September 21st, 2022   \n",
       "1  Taiwan Coffee Laboratory 台灣咖啡研究室  2021 / 2022   November 15th, 2022   \n",
       "2  Taiwan Coffee Laboratory 台灣咖啡研究室  2021 / 2022   November 15th, 2022   \n",
       "3             Japan Coffee Exchange         2022  September 21st, 2022   \n",
       "4             Japan Coffee Exchange         2022       March 6th, 2023   \n",
       "\n",
       "                              Owner      Variety     Status  \\\n",
       "0              Coffee Quality Union     Castillo  Completed   \n",
       "1  Taiwan Coffee Laboratory 台灣咖啡研究室        Gesha  Completed   \n",
       "2  Taiwan Coffee Laboratory 台灣咖啡研究室         Java  Completed   \n",
       "3              Coffee Quality Union        Gesha  Completed   \n",
       "4              Coffee Quality Union  Red Bourbon  Completed   \n",
       "\n",
       "         Processing Method  Aroma  Flavor  Aftertaste  Acidity  Body  Balance  \\\n",
       "0  Double Anaerobic Washed   8.58    8.50        8.42     8.58  8.25     8.42   \n",
       "1             Washed / Wet   8.50    8.50        7.92     8.00  7.92     8.25   \n",
       "2              Semi Washed   8.33    8.42        8.08     8.17  7.92     8.17   \n",
       "3             Washed / Wet   8.08    8.17        8.17     8.25  8.17     8.08   \n",
       "4             Honey,Mossto   8.33    8.33        8.08     8.25  7.92     7.92   \n",
       "\n",
       "   Uniformity  Clean Cup  Sweetness  Overall  Defects  Total Cup Points  \\\n",
       "0        10.0       10.0       10.0     8.58      0.0             89.33   \n",
       "1        10.0       10.0       10.0     8.50      0.0             87.58   \n",
       "2        10.0       10.0       10.0     8.33      0.0             87.42   \n",
       "3        10.0       10.0       10.0     8.25      0.0             87.17   \n",
       "4        10.0       10.0       10.0     8.25      0.0             87.08   \n",
       "\n",
       "   Moisture Percentage  Category One Defects  Quakers         Color  \\\n",
       "0                 11.8                     0        0         green   \n",
       "1                 10.5                     0        0    blue-green   \n",
       "2                 10.4                     0        0     yellowish   \n",
       "3                 11.8                     0        0         green   \n",
       "4                 11.6                     0        2  yellow-green   \n",
       "\n",
       "   Category Two Defects            Expiration  \\\n",
       "0                     3  September 21st, 2023   \n",
       "1                     0   November 15th, 2023   \n",
       "2                     2   November 15th, 2023   \n",
       "3                     0  September 21st, 2023   \n",
       "4                     2       March 5th, 2024   \n",
       "\n",
       "                 Certification Body  \\\n",
       "0             Japan Coffee Exchange   \n",
       "1  Taiwan Coffee Laboratory 台灣咖啡研究室   \n",
       "2  Taiwan Coffee Laboratory 台灣咖啡研究室   \n",
       "3             Japan Coffee Exchange   \n",
       "4             Japan Coffee Exchange   \n",
       "\n",
       "                               Certification Address  \\\n",
       "0  〒413-0002 静岡県熱海市伊豆山１１７３−５８ 1173-58 Izusan, Ata...   \n",
       "1  QAHWAH CO., LTD 4F, No. 225, Sec. 3, Beixin Rd...   \n",
       "2  QAHWAH CO., LTD 4F, No. 225, Sec. 3, Beixin Rd...   \n",
       "3  〒413-0002 静岡県熱海市伊豆山１１７３−５８ 1173-58 Izusan, Ata...   \n",
       "4  〒413-0002 静岡県熱海市伊豆山１１７３−５８ 1173-58 Izusan, Ata...   \n",
       "\n",
       "                     Certification Contact  \n",
       "0  松澤　宏樹　Koju Matsuzawa - +81(0)9085642901  \n",
       "1     Lin, Jen-An Neil 林仁安 - 886-289116612  \n",
       "2     Lin, Jen-An Neil 林仁安 - 886-289116612  \n",
       "3  松澤　宏樹　Koju Matsuzawa - +81(0)9085642901  \n",
       "4  松澤　宏樹　Koju Matsuzawa - +81(0)9085642901  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, rand_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('df_arabica_clean.csv')\n",
    "#sweetness, defects, clean cup and uniformity all 10 for every row\n",
    "# df = df.drop(columns=['ICO Number', 'Unnamed: 0', 'ID', 'Sweetness', 'Clean Cup', 'Defects', 'Uniformity'])\n",
    "df = df.fillna('N/A')\n",
    "rs = 12\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Brazil', 'Colombia', 'Costa Rica', 'El Salvador', 'Ethiopia',\n",
      "       'Guatemala', 'Honduras', 'Indonesia', 'Kenya', 'Laos', 'Madagascar',\n",
      "       'Mexico', 'Myanmar', 'Nicaragua', 'Panama', 'Peru', 'Taiwan',\n",
      "       'Tanzania, United Republic Of', 'Thailand', 'Uganda',\n",
      "       'United States (Hawaii)', 'Vietnam'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numCountries = len(df['Country of Origin'].value_counts())\n",
    "\n",
    "flavMetrics = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance']\n",
    "keepCols = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance', 'Country of Origin']\n",
    "scoreCols = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance']\n",
    "\n",
    "df = df[keepCols]\n",
    "\n",
    "# sns.pairplot(df, hue='Country of Origin')\n",
    "\n",
    "# drop outlier with moisture percentage of 0\n",
    "# df = df.loc[df['Moisture Percentage'] > 0]\n",
    "\n",
    "# converts scores out of 10 to 0-1 scale\n",
    "for i in scoreCols:\n",
    "    df[i] = df[i].apply(lambda x: x / 10.0)\n",
    "\n",
    "# converts moisture percentage to 0-1 scale\n",
    "# df['Moisture Percentage'] = df['Moisture Percentage'].apply(lambda x: x / 100.0)\n",
    "\n",
    "X = df.drop(columns='Country of Origin')\n",
    "y = pd.get_dummies(df['Country of Origin'])\n",
    "\n",
    "countries = y.columns\n",
    "\n",
    "print(countries)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 58ms/step - loss: 0.7805 - accuracy: 0.0194 - val_loss: 0.7571 - val_accuracy: 0.0192\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7456 - accuracy: 0.0194 - val_loss: 0.7273 - val_accuracy: 0.0192\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7179 - accuracy: 0.0194 - val_loss: 0.7030 - val_accuracy: 0.0192\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6950 - accuracy: 0.0194 - val_loss: 0.6824 - val_accuracy: 0.0192\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6753 - accuracy: 0.0129 - val_loss: 0.6643 - val_accuracy: 0.0192\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6578 - accuracy: 0.0194 - val_loss: 0.6478 - val_accuracy: 0.0192\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6416 - accuracy: 0.0194 - val_loss: 0.6324 - val_accuracy: 0.0385\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6269 - accuracy: 0.0452 - val_loss: 0.6193 - val_accuracy: 0.0769\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6142 - accuracy: 0.0581 - val_loss: 0.6068 - val_accuracy: 0.0769\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6017 - accuracy: 0.0581 - val_loss: 0.5943 - val_accuracy: 0.0769\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5891 - accuracy: 0.0581 - val_loss: 0.5815 - val_accuracy: 0.0769\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5762 - accuracy: 0.0581 - val_loss: 0.5684 - val_accuracy: 0.0769\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5628 - accuracy: 0.0581 - val_loss: 0.5548 - val_accuracy: 0.0769\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5490 - accuracy: 0.0581 - val_loss: 0.5407 - val_accuracy: 0.0769\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5347 - accuracy: 0.0581 - val_loss: 0.5259 - val_accuracy: 0.0769\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5197 - accuracy: 0.0581 - val_loss: 0.5105 - val_accuracy: 0.0769\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5041 - accuracy: 0.0581 - val_loss: 0.4945 - val_accuracy: 0.0769\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4878 - accuracy: 0.0581 - val_loss: 0.4778 - val_accuracy: 0.0769\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4709 - accuracy: 0.0581 - val_loss: 0.4605 - val_accuracy: 0.0769\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4534 - accuracy: 0.0581 - val_loss: 0.4427 - val_accuracy: 0.0769\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4355 - accuracy: 0.0581 - val_loss: 0.4245 - val_accuracy: 0.0769\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4172 - accuracy: 0.0581 - val_loss: 0.4059 - val_accuracy: 0.0769\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3987 - accuracy: 0.0581 - val_loss: 0.3872 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3801 - accuracy: 0.0581 - val_loss: 0.3685 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3616 - accuracy: 0.0387 - val_loss: 0.3501 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3434 - accuracy: 0.0452 - val_loss: 0.3321 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3258 - accuracy: 0.0452 - val_loss: 0.3147 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3089 - accuracy: 0.0452 - val_loss: 0.2982 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2930 - accuracy: 0.0452 - val_loss: 0.2827 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2781 - accuracy: 0.0452 - val_loss: 0.2682 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2644 - accuracy: 0.0452 - val_loss: 0.2550 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2519 - accuracy: 0.0452 - val_loss: 0.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2406 - accuracy: 0.0452 - val_loss: 0.2321 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.2306 - accuracy: 0.0452 - val_loss: 0.2225 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2217 - accuracy: 0.0452 - val_loss: 0.2140 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2139 - accuracy: 0.0258 - val_loss: 0.2066 - val_accuracy: 0.3269\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2071 - accuracy: 0.2774 - val_loss: 0.2000 - val_accuracy: 0.3462\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2011 - accuracy: 0.2774 - val_loss: 0.1943 - val_accuracy: 0.3462\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1960 - accuracy: 0.2774 - val_loss: 0.1894 - val_accuracy: 0.3462\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1916 - accuracy: 0.2774 - val_loss: 0.1851 - val_accuracy: 0.3462\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1878 - accuracy: 0.2774 - val_loss: 0.1813 - val_accuracy: 0.3462\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1845 - accuracy: 0.2774 - val_loss: 0.1781 - val_accuracy: 0.3462\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1816 - accuracy: 0.2774 - val_loss: 0.1753 - val_accuracy: 0.3462\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1792 - accuracy: 0.2774 - val_loss: 0.1728 - val_accuracy: 0.3462\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1770 - accuracy: 0.2774 - val_loss: 0.1707 - val_accuracy: 0.3462\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1752 - accuracy: 0.2774 - val_loss: 0.1688 - val_accuracy: 0.3462\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1736 - accuracy: 0.2774 - val_loss: 0.1672 - val_accuracy: 0.3462\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1723 - accuracy: 0.2774 - val_loss: 0.1658 - val_accuracy: 0.3462\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1711 - accuracy: 0.2774 - val_loss: 0.1645 - val_accuracy: 0.3462\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1701 - accuracy: 0.2774 - val_loss: 0.1634 - val_accuracy: 0.3462\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1692 - accuracy: 0.2774 - val_loss: 0.1625 - val_accuracy: 0.3462\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1683 - accuracy: 0.2774 - val_loss: 0.1616 - val_accuracy: 0.3462\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1677 - accuracy: 0.2774 - val_loss: 0.1608 - val_accuracy: 0.3462\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1670 - accuracy: 0.2774 - val_loss: 0.1602 - val_accuracy: 0.3462\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1665 - accuracy: 0.2774 - val_loss: 0.1596 - val_accuracy: 0.3462\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1660 - accuracy: 0.2774 - val_loss: 0.1590 - val_accuracy: 0.3462\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1656 - accuracy: 0.2774 - val_loss: 0.1586 - val_accuracy: 0.3462\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1652 - accuracy: 0.2774 - val_loss: 0.1582 - val_accuracy: 0.3462\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1649 - accuracy: 0.2774 - val_loss: 0.1578 - val_accuracy: 0.3462\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1646 - accuracy: 0.2774 - val_loss: 0.1574 - val_accuracy: 0.3462\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1643 - accuracy: 0.2774 - val_loss: 0.1571 - val_accuracy: 0.3462\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1641 - accuracy: 0.2774 - val_loss: 0.1568 - val_accuracy: 0.3462\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1639 - accuracy: 0.2774 - val_loss: 0.1565 - val_accuracy: 0.3462\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1637 - accuracy: 0.2774 - val_loss: 0.1563 - val_accuracy: 0.3462\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1635 - accuracy: 0.2774 - val_loss: 0.1561 - val_accuracy: 0.3462\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1633 - accuracy: 0.2774 - val_loss: 0.1559 - val_accuracy: 0.3462\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1632 - accuracy: 0.2774 - val_loss: 0.1558 - val_accuracy: 0.3462\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1630 - accuracy: 0.2774 - val_loss: 0.1556 - val_accuracy: 0.3462\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1629 - accuracy: 0.2774 - val_loss: 0.1554 - val_accuracy: 0.3462\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1628 - accuracy: 0.2774 - val_loss: 0.1553 - val_accuracy: 0.3462\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1627 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1626 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1625 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1624 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1623 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1622 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1622 - accuracy: 0.2774 - val_loss: 0.1546 - val_accuracy: 0.3462\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1621 - accuracy: 0.2774 - val_loss: 0.1546 - val_accuracy: 0.3462\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1620 - accuracy: 0.2774 - val_loss: 0.1545 - val_accuracy: 0.3462\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1620 - accuracy: 0.2774 - val_loss: 0.1544 - val_accuracy: 0.3462\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1619 - accuracy: 0.2774 - val_loss: 0.1544 - val_accuracy: 0.3462\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1619 - accuracy: 0.2774 - val_loss: 0.1544 - val_accuracy: 0.3462\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1619 - accuracy: 0.2774 - val_loss: 0.1544 - val_accuracy: 0.3462\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1618 - accuracy: 0.2774 - val_loss: 0.1543 - val_accuracy: 0.3462\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1617 - accuracy: 0.2774 - val_loss: 0.1543 - val_accuracy: 0.3462\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1617 - accuracy: 0.2774 - val_loss: 0.1542 - val_accuracy: 0.3462\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1616 - accuracy: 0.2774 - val_loss: 0.1542 - val_accuracy: 0.3462\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1616 - accuracy: 0.2774 - val_loss: 0.1542 - val_accuracy: 0.3462\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1615 - accuracy: 0.2774 - val_loss: 0.1541 - val_accuracy: 0.3462\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1616 - accuracy: 0.2774 - val_loss: 0.1541 - val_accuracy: 0.3462\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1615 - accuracy: 0.2774 - val_loss: 0.1541 - val_accuracy: 0.3462\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1615 - accuracy: 0.2774 - val_loss: 0.1541 - val_accuracy: 0.3462\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1614 - accuracy: 0.2774 - val_loss: 0.1541 - val_accuracy: 0.3462\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1614 - accuracy: 0.2774 - val_loss: 0.1541 - val_accuracy: 0.3462\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1614 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1613 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1613 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1613 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1613 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1613 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1612 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1612 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1612 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1612 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1611 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1611 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1611 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1611 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1611 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1540 - val_accuracy: 0.3462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)\n",
    "\n",
    "model1 = Sequential([\n",
    "    Dense(6, input_shape=(6,), activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(22, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(SGD(lr = .05), 'binary_crossentropy', metrics=['accuracy'])\n",
    "hist1 = model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, callbacks=[es])\n",
    "\n",
    "val_losses = hist1.history['val_loss']\n",
    "val_accuracies = hist1.history['val_accuracy']\n",
    "epochs = range(1, len(val_losses) + 1)\n",
    "\n",
    "sns.lineplot(x=epochs, y=val_losses, color='red')\n",
    "sns.lineplot(x=epochs, y=val_accuracies, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 51ms/step - loss: 0.7033 - accuracy: 0.0194 - val_loss: 0.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6899 - accuracy: 0.0194 - val_loss: 0.6833 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.0194 - val_loss: 0.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6651 - accuracy: 0.0194 - val_loss: 0.6600 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6545 - accuracy: 0.0194 - val_loss: 0.6497 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6440 - accuracy: 0.0194 - val_loss: 0.6392 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6331 - accuracy: 0.0194 - val_loss: 0.6282 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6217 - accuracy: 0.0194 - val_loss: 0.6166 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6096 - accuracy: 0.0194 - val_loss: 0.6041 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5966 - accuracy: 0.0194 - val_loss: 0.5907 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5825 - accuracy: 0.0194 - val_loss: 0.5762 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5673 - accuracy: 0.0194 - val_loss: 0.5602 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5506 - accuracy: 0.0194 - val_loss: 0.5428 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5324 - accuracy: 0.0194 - val_loss: 0.5238 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5125 - accuracy: 0.0194 - val_loss: 0.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4909 - accuracy: 0.0194 - val_loss: 0.4806 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4676 - accuracy: 0.0194 - val_loss: 0.4564 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4425 - accuracy: 0.0194 - val_loss: 0.4306 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4161 - accuracy: 0.0194 - val_loss: 0.4036 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3887 - accuracy: 0.0194 - val_loss: 0.3759 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3609 - accuracy: 0.0968 - val_loss: 0.3483 - val_accuracy: 0.3462\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3336 - accuracy: 0.2774 - val_loss: 0.3216 - val_accuracy: 0.3462\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3076 - accuracy: 0.2774 - val_loss: 0.2966 - val_accuracy: 0.3462\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2835 - accuracy: 0.2774 - val_loss: 0.2739 - val_accuracy: 0.3462\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2620 - accuracy: 0.2774 - val_loss: 0.2540 - val_accuracy: 0.3462\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2435 - accuracy: 0.2774 - val_loss: 0.2370 - val_accuracy: 0.3462\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2279 - accuracy: 0.2774 - val_loss: 0.2229 - val_accuracy: 0.3462\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2152 - accuracy: 0.2774 - val_loss: 0.2115 - val_accuracy: 0.3462\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2050 - accuracy: 0.2774 - val_loss: 0.2022 - val_accuracy: 0.3462\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1968 - accuracy: 0.2774 - val_loss: 0.1949 - val_accuracy: 0.3462\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1904 - accuracy: 0.2774 - val_loss: 0.1890 - val_accuracy: 0.3462\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1853 - accuracy: 0.2774 - val_loss: 0.1842 - val_accuracy: 0.3462\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1814 - accuracy: 0.2774 - val_loss: 0.1805 - val_accuracy: 0.3462\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1782 - accuracy: 0.2774 - val_loss: 0.1775 - val_accuracy: 0.3462\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1757 - accuracy: 0.2774 - val_loss: 0.1749 - val_accuracy: 0.3462\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1737 - accuracy: 0.2774 - val_loss: 0.1729 - val_accuracy: 0.3462\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1721 - accuracy: 0.2774 - val_loss: 0.1711 - val_accuracy: 0.3462\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1707 - accuracy: 0.2774 - val_loss: 0.1697 - val_accuracy: 0.3462\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1696 - accuracy: 0.2774 - val_loss: 0.1684 - val_accuracy: 0.3462\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1687 - accuracy: 0.2774 - val_loss: 0.1674 - val_accuracy: 0.3462\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1679 - accuracy: 0.2774 - val_loss: 0.1664 - val_accuracy: 0.3462\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1672 - accuracy: 0.2774 - val_loss: 0.1656 - val_accuracy: 0.3462\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1667 - accuracy: 0.2774 - val_loss: 0.1649 - val_accuracy: 0.3462\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1662 - accuracy: 0.2774 - val_loss: 0.1643 - val_accuracy: 0.3462\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1658 - accuracy: 0.2774 - val_loss: 0.1637 - val_accuracy: 0.3462\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1653 - accuracy: 0.2774 - val_loss: 0.1632 - val_accuracy: 0.3462\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1650 - accuracy: 0.2774 - val_loss: 0.1627 - val_accuracy: 0.3462\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1647 - accuracy: 0.2774 - val_loss: 0.1622 - val_accuracy: 0.3462\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1645 - accuracy: 0.2774 - val_loss: 0.1619 - val_accuracy: 0.3462\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1642 - accuracy: 0.2774 - val_loss: 0.1615 - val_accuracy: 0.3462\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1640 - accuracy: 0.2774 - val_loss: 0.1612 - val_accuracy: 0.3462\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1637 - accuracy: 0.2774 - val_loss: 0.1608 - val_accuracy: 0.3462\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1636 - accuracy: 0.2774 - val_loss: 0.1605 - val_accuracy: 0.3462\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1633 - accuracy: 0.2774 - val_loss: 0.1602 - val_accuracy: 0.3462\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1633 - accuracy: 0.2774 - val_loss: 0.1600 - val_accuracy: 0.3462\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1631 - accuracy: 0.2774 - val_loss: 0.1597 - val_accuracy: 0.3462\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1630 - accuracy: 0.2774 - val_loss: 0.1595 - val_accuracy: 0.3462\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1629 - accuracy: 0.2774 - val_loss: 0.1593 - val_accuracy: 0.3462\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1627 - accuracy: 0.2774 - val_loss: 0.1591 - val_accuracy: 0.3462\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1625 - accuracy: 0.2774 - val_loss: 0.1589 - val_accuracy: 0.3462\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1625 - accuracy: 0.2774 - val_loss: 0.1587 - val_accuracy: 0.3462\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1624 - accuracy: 0.2774 - val_loss: 0.1586 - val_accuracy: 0.3462\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1623 - accuracy: 0.2774 - val_loss: 0.1584 - val_accuracy: 0.3462\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1621 - accuracy: 0.2774 - val_loss: 0.1583 - val_accuracy: 0.3462\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1621 - accuracy: 0.2774 - val_loss: 0.1581 - val_accuracy: 0.3462\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1621 - accuracy: 0.2774 - val_loss: 0.1580 - val_accuracy: 0.3462\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1620 - accuracy: 0.2774 - val_loss: 0.1578 - val_accuracy: 0.3462\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1619 - accuracy: 0.2774 - val_loss: 0.1577 - val_accuracy: 0.3462\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1618 - accuracy: 0.2774 - val_loss: 0.1576 - val_accuracy: 0.3462\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1617 - accuracy: 0.2774 - val_loss: 0.1575 - val_accuracy: 0.3462\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1617 - accuracy: 0.2774 - val_loss: 0.1574 - val_accuracy: 0.3462\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1616 - accuracy: 0.2774 - val_loss: 0.1573 - val_accuracy: 0.3462\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1616 - accuracy: 0.2774 - val_loss: 0.1572 - val_accuracy: 0.3462\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1616 - accuracy: 0.2774 - val_loss: 0.1571 - val_accuracy: 0.3462\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1615 - accuracy: 0.2774 - val_loss: 0.1570 - val_accuracy: 0.3462\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1614 - accuracy: 0.2774 - val_loss: 0.1569 - val_accuracy: 0.3462\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1614 - accuracy: 0.2774 - val_loss: 0.1568 - val_accuracy: 0.3462\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1614 - accuracy: 0.2774 - val_loss: 0.1568 - val_accuracy: 0.3462\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1613 - accuracy: 0.2774 - val_loss: 0.1567 - val_accuracy: 0.3462\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1613 - accuracy: 0.2774 - val_loss: 0.1567 - val_accuracy: 0.3462\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1613 - accuracy: 0.2774 - val_loss: 0.1566 - val_accuracy: 0.3462\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1612 - accuracy: 0.2774 - val_loss: 0.1566 - val_accuracy: 0.3462\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1612 - accuracy: 0.2774 - val_loss: 0.1565 - val_accuracy: 0.3462\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1612 - accuracy: 0.2774 - val_loss: 0.1564 - val_accuracy: 0.3462\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1612 - accuracy: 0.2774 - val_loss: 0.1563 - val_accuracy: 0.3462\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1611 - accuracy: 0.2774 - val_loss: 0.1563 - val_accuracy: 0.3462\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1611 - accuracy: 0.2774 - val_loss: 0.1563 - val_accuracy: 0.3462\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1562 - val_accuracy: 0.3462\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1611 - accuracy: 0.2774 - val_loss: 0.1561 - val_accuracy: 0.3462\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1561 - val_accuracy: 0.3462\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1560 - val_accuracy: 0.3462\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1560 - val_accuracy: 0.3462\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1610 - accuracy: 0.2774 - val_loss: 0.1559 - val_accuracy: 0.3462\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1609 - accuracy: 0.2774 - val_loss: 0.1559 - val_accuracy: 0.3462\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1609 - accuracy: 0.2774 - val_loss: 0.1559 - val_accuracy: 0.3462\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1609 - accuracy: 0.2774 - val_loss: 0.1558 - val_accuracy: 0.3462\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1609 - accuracy: 0.2774 - val_loss: 0.1558 - val_accuracy: 0.3462\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1609 - accuracy: 0.2774 - val_loss: 0.1558 - val_accuracy: 0.3462\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1609 - accuracy: 0.2774 - val_loss: 0.1557 - val_accuracy: 0.3462\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1609 - accuracy: 0.2774 - val_loss: 0.1557 - val_accuracy: 0.3462\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1609 - accuracy: 0.2774 - val_loss: 0.1557 - val_accuracy: 0.3462\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1609 - accuracy: 0.2774 - val_loss: 0.1556 - val_accuracy: 0.3462\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1608 - accuracy: 0.2774 - val_loss: 0.1556 - val_accuracy: 0.3462\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1608 - accuracy: 0.2774 - val_loss: 0.1556 - val_accuracy: 0.3462\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1608 - accuracy: 0.2774 - val_loss: 0.1556 - val_accuracy: 0.3462\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1608 - accuracy: 0.2774 - val_loss: 0.1555 - val_accuracy: 0.3462\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1608 - accuracy: 0.2774 - val_loss: 0.1555 - val_accuracy: 0.3462\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1608 - accuracy: 0.2774 - val_loss: 0.1555 - val_accuracy: 0.3462\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.1608 - accuracy: 0.2774 - val_loss: 0.1554 - val_accuracy: 0.3462\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1608 - accuracy: 0.2774 - val_loss: 0.1554 - val_accuracy: 0.3462\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1554 - val_accuracy: 0.3462\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1554 - val_accuracy: 0.3462\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1554 - val_accuracy: 0.3462\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1553 - val_accuracy: 0.3462\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1553 - val_accuracy: 0.3462\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1553 - val_accuracy: 0.3462\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1553 - val_accuracy: 0.3462\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1553 - val_accuracy: 0.3462\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.2774 - val_loss: 0.1552 - val_accuracy: 0.3462\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1551 - val_accuracy: 0.3462\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1550 - val_accuracy: 0.3462\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1606 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1549 - val_accuracy: 0.3462\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1548 - val_accuracy: 0.3462\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1604 - accuracy: 0.2774 - val_loss: 0.1547 - val_accuracy: 0.3462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "es = keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)\n",
    "model2 = Sequential([\n",
    "    Dense(6, input_shape=(6,), activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(22, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(SGD(lr = .05), 'binary_crossentropy', metrics=['accuracy'])\n",
    "hist2 = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, callbacks=[es])\n",
    "\n",
    "val_losses = hist2.history['val_loss']\n",
    "val_accuracies = hist2.history['val_accuracy']\n",
    "epochs = range(1, len(val_losses) + 1)\n",
    "\n",
    "sns.lineplot(x=epochs, y=val_losses, color='red')\n",
    "sns.lineplot(x=epochs, y=val_accuracies, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 6) for input KerasTensor(type_spec=TensorSpec(shape=(None, 6), dtype=tf.float32, name='dense_112_input'), name='dense_112_input', description=\"created by layer 'dense_112_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_36\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_112\" is incompatible with the layer: expected axis -1 of input shape to have value 6, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_36\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3t/s31r6vgj44n_g5t4csrvklwh0000gn/T/ipykernel_62980/698013237.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcountries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/derek/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_36\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_112\" is incompatible with the layer: expected axis -1 of input shape to have value 6, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_36\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
